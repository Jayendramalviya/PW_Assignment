{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Using Conditional Probability  \n",
    "\n",
    "\n",
    "Given Data:  \n",
    "- P(Uses Insurance) = 0.70  \n",
    "- P(Smoker | Uses Insurance) = 0.40  \n",
    "\n",
    "#### Using Conditional Probability Formula:  \n",
    "P(Smoker | Uses Insurance) = frac{P(Smoker \\cap Uses Insurance)}{P(Uses Insurance)}\n",
    "\n",
    "Since P(Smoker | Uses Insurance) is already given as **0.40**, we can directly state:  \n",
    "P(Smoker | Uses Insurance) = 0.40\n",
    "\n",
    "#### Final Answer:  \n",
    "**The probability that an employee is a smoker given that they use the health insurance plan is 0.40 (or 40%). ✅**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference Between Bernoulli Naïve Bayes and Multinomial Naïve Bayes  \n",
    "\n",
    "| Feature                | Bernoulli Naïve Bayes | Multinomial Naïve Bayes |\n",
    "|------------------------|---------------------- |-------------------------|\n",
    "| Data Type              | Binary (0 or 1)       | Count-based (integer frequencies) |\n",
    "| Use Case               | Text classification with word presence/absence | Text classification with word frequency |\n",
    "| Feature Representation | Boolean (Word exists or not) | Counts of words in a document |\n",
    "| Example Application    | Spam detection, fraud detection | Sentiment analysis, topic classification |\n",
    "| Assumption             | Features are independent binary variables | Features follow a multinomial distribution |\n",
    "\n",
    "✅ **Key Takeaway:**  \n",
    "- **Use BernoulliNB** when dealing with binary (yes/no) features.  \n",
    "- **Use MultinomialNB** when working with word frequencies or count-based features.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Bernoulli Naïve Bayes Handles Missing Values  \n",
    "\n",
    "1. **Assumes Missing as Absent (0)**  \n",
    "   - Since Bernoulli Naïve Bayes works with binary features (0 or 1), missing values are often treated as **0** (absence of a feature).  \n",
    "\n",
    "2. **Imputation Strategies**  \n",
    "   - If missing values are significant, common imputation techniques include:  \n",
    "     - **Mode Imputation**: Replacing missing values with the most frequent value (0 or 1).  \n",
    "     - **Mean/Median Imputation**: Using the average presence rate of a feature across samples.  \n",
    "\n",
    "3. **Ignoring Missing Values (During Training)**  \n",
    "   - Some implementations of BernoulliNB may ignore missing values when calculating probabilities to avoid bias.  \n",
    "\n",
    "✅ **Key Takeaway:**  \n",
    "- BernoulliNB assumes missing values as absent (0) by default but can be handled using imputation techniques if needed.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can Gaussian Naïve Bayes Be Used for Multi-Class Classification?  \n",
    "\n",
    "✅ **Yes, Gaussian Naïve Bayes (GNB) can be used for multi-class classification.**  \n",
    "\n",
    "### How It Works:  \n",
    "- GaussianNB assumes that features follow a **normal (Gaussian) distribution**.  \n",
    "- It calculates the probability for each class using Bayes' theorem and assigns the instance to the class with the highest probability.  \n",
    "- The classifier supports **multiple classes (not just binary classification).**  \n",
    "\n",
    "### Example Use Cases:  \n",
    "- **Iris Classification** (classifying flowers into different species).  \n",
    "- **Handwritten Digit Recognition** (classifying digits 0-9).  \n",
    "\n",
    "### Key Takeaway:  \n",
    "- **GaussianNB supports multi-class classification** by computing probabilities for all classes and selecting the most likely one.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Naïve Bayes Classifiers on Spambase Dataset:\n",
      "\n",
      "--- Bernoulli Naïve Bayes ---\n",
      "Accuracy: 0.8762\n",
      "Precision: 0.8716\n",
      "Recall: 0.8044\n",
      "F1 Score: 0.8367\n",
      "Cross-Validation Accuracy: 0.8839\n",
      "\n",
      "\n",
      "--- Multinomial Naïve Bayes ---\n",
      "Accuracy: 0.7763\n",
      "Precision: 0.7199\n",
      "Recall: 0.7080\n",
      "F1 Score: 0.7139\n",
      "Cross-Validation Accuracy: 0.7863\n",
      "\n",
      "\n",
      "--- Gaussian Naïve Bayes ---\n",
      "Accuracy: 0.8328\n",
      "Precision: 0.7146\n",
      "Recall: 0.9587\n",
      "F1 Score: 0.8188\n",
      "Cross-Validation Accuracy: 0.8218\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "columns = [f'feature_{i}' for i in range(57)] + ['label']\n",
    "data = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "# Split features and target\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]    # Labels (Spam or Not Spam)\n",
    "\n",
    "# Standardizing the data for GaussianNB\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting data into training and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Bernoulli Naïve Bayes\": BernoulliNB(),\n",
    "    \"Multinomial Naïve Bayes\": MultinomialNB(),\n",
    "    \"Gaussian Naïve Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Evaluate models using 10-fold cross-validation\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == \"Gaussian Naïve Bayes\":\n",
    "        X_train_fit = scaler.fit_transform(X_train)\n",
    "        X_test_fit = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train_fit, X_test_fit = X_train, X_test\n",
    "\n",
    "    # Train and test the model\n",
    "    model.fit(X_train_fit, y_train)\n",
    "    y_pred = model.predict(X_test_fit)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Cross-validation scores\n",
    "    cross_val = cross_val_score(model, X, y, cv=10, scoring='accuracy').mean()\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Cross-Validation Accuracy\": cross_val\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "print(\"Performance of Naïve Bayes Classifiers on Spambase Dataset:\\n\")\n",
    "for model, metrics in results.items():\n",
    "    print(f\"--- {model} ---\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
