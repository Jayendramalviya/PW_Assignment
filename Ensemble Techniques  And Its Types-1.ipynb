{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is an ensemble technique in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble techniques combine multiple models to improve predictive performance, reduce overfitting, and increase stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Why are ensemble techniques used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble techniques enhance accuracy, reduce bias and variance, and provide more robust predictions by aggregating multiple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What is bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging (Bootstrap Aggregating) is an ensemble technique that trains multiple models on different bootstrap samples of the dataset and averages their predictions to reduce variance (e.g., Random Forest).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What is boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting is an iterative ensemble technique where models are trained sequentially, with each model correcting the errors of the previous one, reducing bias (e.g., AdaBoost, XGBoost)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. What are the benefits of using ensemble techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improves accuracy and robustness\n",
    "\n",
    "Reduces variance and bias\n",
    "\n",
    "Handles complex relationships in data\n",
    "\n",
    "Reduces overfitting (especially bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Are ensemble techniques always better than individual models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not always. They may not help if individual models are weak or if the dataset is small. They also increase complexity and computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. How is the confidence interval calculated using bootstrap?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw multiple resamples from the dataset with replacement.\n",
    "\n",
    "Compute the statistic (e.g., mean) for each resample.\n",
    "\n",
    "Use percentiles (e.g., 2.5% and 97.5%) to estimate the confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. How does bootstrap work and What are the steps involved in bootstrap?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly resample the dataset with replacement.\n",
    "\n",
    "Compute the desired statistic (e.g., mean, median) for each sample.\n",
    "\n",
    "Repeat steps 1 and 2 multiple times.\n",
    "\n",
    "Use the distribution of the resampled statistics to estimate confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a\n",
    "sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use\n",
    "bootstrap to estimate the 95% confidence interval for the population mean height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.450943523508055 15.55333161411026\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap method to estimate 95% confidence interval for mean height\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "sample_mean = 15  # Mean height of sample trees (meters)\n",
    "sample_std = 2     # Standard deviation of sample trees (meters)\n",
    "n = 50            # Sample size\n",
    "n_bootstrap = 10000  # Number of bootstrap samples\n",
    "\n",
    "# Generate bootstrap samples (assuming normal distribution)\n",
    "bootstrap_means = np.random.normal(loc=sample_mean, scale=sample_std/np.sqrt(n), size=n_bootstrap)\n",
    "\n",
    "# Compute 95% confidence interval (percentile method)\n",
    "ci_lower = np.percentile(bootstrap_means, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "print(ci_lower, ci_upper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
