{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach?\n",
    "Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach? Explain with an example.\n",
    "\n",
    "Eigenvalues and eigenvectors are fundamental concepts in linear algebra that help in understanding linear transformations.\n",
    "\n",
    "- **Eigenvector**: A nonzero vector **v** that only changes by a scalar factor when a linear transformation **A** is applied.  \n",
    "- **Eigenvalue**: The scalar **Œª** associated with an eigenvector, representing how much the eigenvector is scaled during the transformation.  \n",
    "\n",
    "Mathematically, this is expressed as:  \n",
    "A v = Œª v  \n",
    "where **A** is a square matrix, **v** is an eigenvector, and **Œª** is the corresponding eigenvalue.\n",
    "\n",
    "### Relation to Eigen-Decomposition  \n",
    "Eigen-decomposition is the process of decomposing a square matrix **A** into its eigenvalues and eigenvectors:  \n",
    "A = P D P‚Åª¬π  \n",
    "where:  \n",
    "- **P** is the matrix of eigenvectors,  \n",
    "- **D** is a diagonal matrix containing eigenvalues,  \n",
    "- **P‚Åª¬π** is the inverse of **P**.\n",
    "\n",
    "### Example  \n",
    "Consider the matrix:  \n",
    "A = | 4  2 |  \n",
    "    | 1  3 |  \n",
    "\n",
    "To find eigenvalues, solve **det(A - ŒªI) = 0**:  \n",
    "| 4-Œª  2  |  \n",
    "| 1   3-Œª | = 0  \n",
    "\n",
    "(4-Œª)(3-Œª) - (2)(1) = 0  \n",
    "Œª¬≤ - 7Œª + 10 = 0  \n",
    "\n",
    "Solving, we get **Œª = 5, 2**.\n",
    "\n",
    "For **Œª = 5**, solving (A - 5I)v = 0 gives eigenvector **v = [2,1]**.  \n",
    "For **Œª = 2**, solving (A - 2I)v = 0 gives eigenvector **v = [-1,1]**.  \n",
    "\n",
    "Thus, **A** can be decomposed as:  \n",
    "A = P D P‚Åª¬π  \n",
    "where  \n",
    "P = |  2  -1 |  \n",
    "    |  1   1 |  \n",
    "\n",
    "D = | 5  0 |  \n",
    "    | 0  2 |  \n",
    "\n",
    "This decomposition is useful in various applications like PCA, image processing, and stability analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What is eigen decomposition and what is its significance in linear algebra?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What is eigen decomposition and what is its significance in linear algebra?\n",
    "\n",
    "### Eigen Decomposition:\n",
    "Eigen decomposition (or spectral decomposition) is a matrix factorization technique where a square matrix **A** is decomposed into its eigenvalues and eigenvectors.\n",
    "\n",
    "Mathematically, if **A** is an **n √ó n** matrix, it can be written as:  \n",
    "A = P D P‚Åª¬π  \n",
    "where:  \n",
    "- **P** is the matrix of eigenvectors of **A**  \n",
    "- **D** is a diagonal matrix containing the eigenvalues of **A**  \n",
    "- **P‚Åª¬π** is the inverse of **P**\n",
    "\n",
    "### Significance in Linear Algebra:\n",
    "1. **Simplifies Matrix Computations**:  \n",
    "   - Powers of **A** can be computed easily using A‚Åø = P D‚Åø P‚Åª¬π.\n",
    "   - Useful in solving differential equations and dynamic systems.\n",
    "\n",
    "2. **Dimensionality Reduction (PCA)**:  \n",
    "   - Principal Component Analysis (PCA) uses eigen decomposition to identify important directions (principal components) in data.\n",
    "\n",
    "3. **Understanding Linear Transformations**:  \n",
    "   - Eigenvectors represent the directions that remain unchanged under transformation, while eigenvalues indicate the scale of transformation.\n",
    "\n",
    "4. **Graph Theory and Network Analysis**:  \n",
    "   - Eigenvalues of adjacency matrices help analyze connectivity and stability of networks.\n",
    "\n",
    "5. **Quantum Mechanics and Physics**:  \n",
    "   - Used in solving Schr√∂dinger‚Äôs equation in quantum mechanics.\n",
    "\n",
    "Eigen decomposition is a fundamental concept in mathematics, data science, and machine learning, providing deep insights into matrix properties and transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What is eigen decomposition and what is its significance in linear algebra?\n",
    "\n",
    "### Eigen Decomposition:\n",
    "Eigen decomposition (or spectral decomposition) is a matrix factorization technique where a square matrix **A** is decomposed into its eigenvalues and eigenvectors.\n",
    "\n",
    "Mathematically, if **A** is an **n √ó n** matrix, it can be written as:  \n",
    "A = P D P‚Åª¬π  \n",
    "where:  \n",
    "- **P** is the matrix of eigenvectors of **A**  \n",
    "- **D** is a diagonal matrix containing the eigenvalues of **A**  \n",
    "- **P‚Åª¬π** is the inverse of **P**\n",
    "\n",
    "### Significance in Linear Algebra:\n",
    "1. **Simplifies Matrix Computations**:  \n",
    "   - Powers of **A** can be computed easily using A‚Åø = P D‚Åø P‚Åª¬π.\n",
    "   - Useful in solving differential equations and dynamic systems.\n",
    "\n",
    "2. **Dimensionality Reduction (PCA)**:  \n",
    "   - Principal Component Analysis (PCA) uses eigen decomposition to identify important directions (principal components) in data.\n",
    "\n",
    "3. **Understanding Linear Transformations**:  \n",
    "   - Eigenvectors represent the directions that remain unchanged under transformation, while eigenvalues indicate the scale of transformation.\n",
    "\n",
    "4. **Graph Theory and Network Analysis**:  \n",
    "   - Eigenvalues of adjacency matrices help analyze connectivity and stability of networks.\n",
    "\n",
    "5. **Quantum Mechanics and Physics**:  \n",
    "   - Used in solving Schr√∂dinger‚Äôs equation in quantum mechanics.\n",
    "\n",
    "Eigen decomposition is a fundamental concept in mathematics, data science, and machine learning, providing deep insights into matrix properties and transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What are the conditions that must be satisfied for a square matrix to be diagonalizable using the\n",
    "Eigen-Decomposition approach? Provide a brief proof to support your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A square matrix A is diagonalizable if:\n",
    "- It has ùëõ linearly independent eigenvectors (for an n√ón matrix).\n",
    "- The algebraic multiplicity of each eigenvalue equals its geometric multiplicity.\n",
    "\n",
    "\n",
    "Proof Sketch\n",
    "If A has ùëõ linearly independent eigenvectors, they form the matrix P allowing decomposition:\n",
    "A=PDP-\n",
    "\n",
    "\n",
    "where \n",
    "\n",
    "D is diagonal, making A diagonalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach?\n",
    "How is it related to the diagonalizability of a matrix? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What is the significance of the spectral theorem in Eigen-Decomposition?\n",
    "\n",
    "### Spectral Theorem:\n",
    "The **Spectral Theorem** states that a **symmetric matrix** (A = A·µÄ) can be **diagonalized** using an orthogonal matrix.\n",
    "\n",
    "### Significance:\n",
    "1. **Orthogonal Diagonalization**: A symmetric matrix **A** can be written as:\n",
    "   \\[\n",
    "   A = Q D Q^T\n",
    "   \\]\n",
    "   where **Q** is an orthogonal matrix (Q‚Åª¬π = Q·µÄ), and **D** is a diagonal matrix of eigenvalues.\n",
    "   \n",
    "2. **Real Eigenvalues**: A symmetric matrix always has **real** eigenvalues.\n",
    "\n",
    "3. **Orthogonal Eigenvectors**: Eigenvectors of a symmetric matrix are **orthogonal**, making computations stable.\n",
    "\n",
    "4. **Applications**:\n",
    "   - **PCA (Principal Component Analysis)**: Uses spectral decomposition to reduce dimensions.\n",
    "   - **Quantum Mechanics**: Represents quantum states.\n",
    "   - **Graph Theory**: Analyzes adjacency matrices of graphs.\n",
    "\n",
    "### Conclusion:\n",
    "The Spectral Theorem ensures that **symmetric matrices** are always diagonalizable with **orthogonal eigenvectors**, simplifying many mathematical and computational problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. How do you find the eigenvalues of a matrix and what do they represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find eigenvalues of matrix ùê¥:\n",
    "Solve characteristic equation\n",
    "|ùê¥ ‚àí ùúÜùêº| = 0\n",
    "Solve for ùúÜ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. What are eigenvectors and how are they related to eigenvalues?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenvectors are special vectors ùë£ that satisfy:\n",
    "Av=Œªv\n",
    "where \n",
    "ùúÜ is an eigenvalue.\n",
    "\n",
    "\n",
    "Relationship:\n",
    "Eigenvectors point in directions that remain unchanged under transformation, and eigenvalues tell how much they scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Can you explain the geometric interpretation of eigenvectors and eigenvalues?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úî Eigenvectors define directions in which transformations occur.\n",
    "\n",
    "‚úî Eigenvalues indicate the factor of stretching/shrinking in those directions.\n",
    "\n",
    "Example:\n",
    "For rotation matrices, eigenvectors give axes of rotation.\n",
    "\n",
    "For scaling matrices, eigenvalues indicate stretching factors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. What are some real-world applications of eigen decomposition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úî PCA (Principal Component Analysis): Finds directions of maximum variance.\n",
    "\n",
    "‚úî Vibration analysis: Eigenvalues determine natural frequencies\n",
    "\n",
    "‚úî Google PageRank: Uses eigenvectors to rank web pages.\n",
    "\n",
    "‚úî Quantum mechanics: Schr√∂dinger equation solutions involve eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. Can a matrix have more than one set of eigenvectors and eigenvalues?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úî Yes, but only for defective matrices where eigenvectors are not independent.\n",
    "\n",
    "‚úî Unique eigenvalues ‚Üí unique eigenvectors (up to scaling).\n",
    "\n",
    "‚úî Repeated eigenvalues may have different sets of eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. In what ways is the Eigen-Decomposition approach useful in data analysis and machine learning?\n",
    "Discuss at least three specific applications or techniques that rely on Eigen-Decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1Ô∏è‚É£ PCA (Principal Component Analysis): Reduces dimensionality by selecting eigenvectors of the covariance matrix.\n",
    "\n",
    "2Ô∏è‚É£ Spectral Clustering: Uses eigenvalues of similarity matrices for clustering.\n",
    "\n",
    "3Ô∏è‚É£ Latent Semantic Analysis (LSA): Eigen decomposition helps in NLP for document similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
