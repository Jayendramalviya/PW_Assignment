{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest Regressor is an ensemble learning algorithm that uses multiple decision trees to make regression predictions. It is an extension of bagging, where each tree is trained on a different bootstrap sample of the data, and the final prediction is obtained by averaging the outputs of all trees.\n",
    "\n",
    "Key Features:\n",
    "\n",
    "Reduces overfitting compared to a single decision tree.\n",
    "\n",
    "Handles non-linear relationships well.\n",
    "\n",
    "Works efficiently on large datasets.\n",
    "\n",
    "Can handle missing values and outliers effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging (Bootstrap Aggregation): Trains multiple trees on different random subsets of data.\n",
    "\n",
    "‚úÖ Feature Randomness: Uses random subsets of features at each split, reducing correlation between trees.\n",
    "\n",
    "‚úÖ Averaging Predictions: Final output is the average of all trees, smoothing noise and preventing overfitting.\n",
    "\n",
    "‚úÖ Hyperparameter Tuning: Limits tree depth (max_depth), minimum samples (min_samples_split) to prevent overly complex trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "\n",
    "- Random Forest Regressor aggregates predictions using **averaging**:\n",
    "  1. Multiple decision trees are trained on different random subsets of data.\n",
    "  2. Each tree makes an independent prediction for the given input.\n",
    "  3. The final prediction is computed as the **average** of all tree outputs:\n",
    "\n",
    "     Formula:\n",
    "     ùë¶ÃÇ = (1/N) ‚àë ùë¶·µ¢\n",
    "\n",
    "     where **N** is the number of trees and **y·µ¢** is the prediction of the i-th tree.\n",
    "\n",
    "Averaging reduces variance and improves model stability! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What are the hyperparameters of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "\n",
    "1. **n_estimators** - Number of trees in the forest.\n",
    "2. **max_depth** - Maximum depth of each tree.\n",
    "3. **min_samples_split** - Minimum samples needed to split a node.\n",
    "4. **min_samples_leaf** - Minimum samples needed in a leaf node.\n",
    "5. **max_features** - Number of features considered at each split.\n",
    "6. **bootstrap** - Whether to use random sampling with replacement.\n",
    "7. **oob_score** - Use out-of-bag samples for validation.\n",
    "8. **random_state** - Controls randomness for reproducibility.\n",
    "\n",
    "‚úÖ Adjusting these helps improve accuracy and prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Regressor**: Uses multiple decision trees and averages their predictions, reducing overfitting.\n",
    "\n",
    "\n",
    "**Decision Tree Regressor**: Uses a single decision tree, which may overfit the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages**:\n",
    "\n",
    "- Reduces overfitting by averaging multiple trees.\n",
    "\n",
    "- Handles missing values and noisy data well.\n",
    "\n",
    "- Works well with both small and large datasets.\n",
    "\n",
    "\n",
    "\n",
    " **Disadvantages**:\n",
    "- Slower than a single decision tree.\n",
    "\n",
    "- Requires more memory and computation.\n",
    "\n",
    "- Less interpretable than a single decision tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. What is the output of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It outputs the **average prediction** from all decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No, **Random Forest Regressor** is for regression tasks.\n",
    "- However, **Random Forest Classifier** is used for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
