{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is a projection and how is it used in PCA?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A projection is the process of mapping data points from a higher-dimensional space onto a lower-dimensional subspace. In PCA, data points are projected onto a set of new axes called principal components, which maximize variance while minimizing information loss.\n",
    "\n",
    "Example: In a 2D dataset, PCA can project points onto a 1D line that best represents the data spread.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. How does the optimization problem in PCA work, and what is it trying to achieve?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA solves an optimization problem to find the directions (principal components) that maximize variance in the data. It does this by:\n",
    "\n",
    "Computing the covariance matrix of the data.\n",
    "- Finding the eigenvectors and eigenvalues of this matrix.\n",
    "- Selecting eigenvectors (principal components) corresponding to the largest eigenvalues.\n",
    "- Goal: Reduce dimensionality while retaining the most important information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What is the relationship between covariance matrices and PCA?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance matrix captures relationships between features. PCA uses it to:\n",
    "\n",
    "âœ… Identify correlated features.\n",
    "\n",
    "âœ… Find eigenvalues and eigenvectors, which define the principal components.\n",
    "\n",
    "âœ… Rank principal components by their variance (higher variance = more important).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. How does the choice of number of principal components impact the performance of PCA?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Too many components â†’ Overfitting (includes noise, computationally expensive).\n",
    "- Too few components â†’ Information loss (important patterns removed).\n",
    "- Ideal choice: Keep enough components to preserve ~90-95% variance (using the explained variance ratio)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. How can PCA be used in feature selection, and what are the benefits of using it for this purpose?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA selects features by transforming them into new uncorrelated variables (principal components).\n",
    "\n",
    "âœ… Reduces dimensionality (fewer features, faster training).\n",
    "\n",
    "âœ… Removes multicollinearity (principal components are uncorrelated).\n",
    "\n",
    "âœ… Improves visualization (reduces complexity for plotting in 2D or 3D).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. What are some common applications of PCA in data science and machine learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“Š Dimensionality reduction â€“ Reducing feature space for efficiency.\n",
    "\n",
    "ðŸ“ˆ Data visualization â€“ Projecting high-dimensional data to 2D or 3D.\n",
    "\n",
    "ðŸ“‰ Noise filtering â€“ Removing less informative components.\n",
    "\n",
    "ðŸ¤– Feature extraction â€“ Creating new features from raw data.\n",
    "\n",
    "ðŸ“· Image compression â€“ Reducing pixel dimensions in image processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7.What is the relationship between spread and variance in PCA?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spread refers to how widely data points are distributed.\n",
    "- Variance quantifies this spread mathematically.\n",
    "- PCA identifies directions (principal components) with maximum variance, assuming these directions contain the most useful information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. How does PCA use the spread and variance of the data to identify principal components?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PCA calculates the covariance matrix to measure data spread.\n",
    "2. It finds eigenvectors (directions) and eigenvalues (variance in those directions).\n",
    "3. It selects the top components that capture the most variance (spread)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. How does PCA handle data with high variance in some dimensions but low variance in others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA prioritizes high-variance dimensions (first components capture most variance).\n",
    "- Low-variance dimensions may be ignored if they contribute little information.\n",
    "- Standardization (scaling) helps balance different scales before applying PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
