{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is a contingency matrix, and how is it used to evaluate the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A contingency matrix is a table used to evaluate classification models by comparing predicted and actual class labels.\n",
    "\n",
    "Usage:\n",
    "- Rows represent actual classes.\n",
    "- Columns represent predicted classes.\n",
    "- Helps in computing evaluation metrics like precision, recall, and F1-score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. How is a pair confusion matrix different from a regular confusion matrix, and why might it be useful in\n",
    "certain situations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A regular confusion matrix evaluates classification performance by counting instances of correct and incorrect predictions.\n",
    "- A pair confusion matrix is used in clustering, comparing pairs of points to assess agreement or disagreement.\n",
    "- Useful in clustering problems where class labels are unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What is an extrinsic measure in the context of natural language processing, and how is it typically\n",
    "used to evaluate the performance of language models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluates model performance based on its impact on an external task.\n",
    "- Examples: BLEU score for machine translation, accuracy in speech recognition.\n",
    "- Measures real-world effectiveness rather than internal model quality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What is an intrinsic measure in the context of machine learning, and how does it differ from an\n",
    "extrinsic measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intrinsic measures assess the model itself without external tasks (e.g., perplexity in language models).\n",
    "- Extrinsic measures evaluate performance based on real-world application results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. What is the purpose of a confusion matrix in machine learning, and how can it be used to identify\n",
    "strengths and weaknesses of a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Provides a detailed breakdown of classification results.\n",
    "- Helps identify model weaknesses (e.g., false positives, false negatives).\n",
    "- Used to derive metrics like precision, recall, and F1-score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. What are some common intrinsic measures used to evaluate the performance of unsupervised\n",
    "learning algorithms, and how can they be interpreted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Silhouette Score: Measures cluster separation.\n",
    "- Davies-Bouldin Index: Evaluates compactness and separation.\n",
    "- Adjusted Rand Index (ARI): Measures clustering similarity with ground truth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. What are some limitations of using accuracy as a sole evaluation metric for classification tasks, and\n",
    "how can these limitations be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Accuracy can be misleading in imbalanced datasets.\n",
    "- Does not distinguish between false positives and false negatives.\n",
    "- Alternatives: Precision, recall, F1-score, ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
